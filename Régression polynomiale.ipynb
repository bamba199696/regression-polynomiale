{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Régression polynomiale.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"89g5Prcjzy5x","executionInfo":{"status":"ok","timestamp":1634290361776,"user_tz":-120,"elapsed":799,"user":{"displayName":"Defarsci Data Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18366965266160858638"}}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.linear_model import LinearRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import mean_squared_error"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ir42i2-Yzy52"},"source":["# Introduction"]},{"cell_type":"markdown","metadata":{"id":"rvYxgIx4zy54"},"source":["Dans ce notebook, nous allons étudier les fondamentaux de la régression polynomiale et mettre en place notre premier projet de Machine Learning.\n","\n","Pour rappel, un polynôme `p(x)` de degré `d` est une fonction mathématique définie par $p(x) = \\theta_{0} + \\theta_{1} x + \\theta_{2} x^{2} + \\ldots + \\theta_{d} x^{d}$."]},{"cell_type":"markdown","metadata":{"id":"AfxhVTBuzy55"},"source":["# Objectifs pédagogiques\n","\n","* Comprendre ce qu'est un polynôme ;\n","* Comprendre ce qu'est un paramètre d'un modèle de Machine Learning ;\n","* Comprendre ce qu'est un hyper-paramètre d'un modèle de Machine Learning ;\n","* S'initier aux notions de sous-apprentissage (\"underfitting\") et de sur-apprentissage (\"overfitting\") ;\n","* Savoir répartir ses données dans un projet de Machine Learning."]},{"cell_type":"markdown","metadata":{"id":"L42npoF1zy56"},"source":["# Préparation des données"]},{"cell_type":"markdown","metadata":{"id":"ru9R8UKizy58"},"source":["## Chargement des données"]},{"cell_type":"markdown","metadata":{"id":"GnMAK3j7zy58"},"source":["Charger respectivement dans une variable `x` et dans une variable `y`, les tableaux `x.npy` et `y.npy`.\n","\n","Astuce : utiliser la fonction Numpy `load()`."]},{"cell_type":"code","metadata":{"id":"beLTJKrGzy58","colab":{"base_uri":"https://localhost:8080/","height":338},"executionInfo":{"status":"error","timestamp":1634290368351,"user_tz":-120,"elapsed":258,"user":{"displayName":"Defarsci Data Lab","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"18366965266160858638"}},"outputId":"2f29876d-9df9-4750-8cfe-a82c133e0e0d"},"source":["x = np.load('x.npy')\n","# y = ..."],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-8f21cab12975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# y = ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'x.npy'"]}]},{"cell_type":"markdown","metadata":{"id":"O3cgwF5Uzy5-"},"source":["## Affichage des données"]},{"cell_type":"code","metadata":{"id":"-qTSh-0Qzy5_"},"source":["# plt.plot(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TjMh1mkCzy6A"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"qPwpoU_-zy6B"},"source":["![](figure1.png)"]},{"cell_type":"markdown","metadata":{"id":"4BU3zUMazy6B"},"source":["Ce jeu de données nous donne l'évolution de la température au cours du temps depuis ces quinze dernières années. Le but est de mettre en place un modèle de Machine Learning capable de prédire la valeur de la température en fonction de la date."]},{"cell_type":"markdown","metadata":{"id":"v08M8_RWzy6C"},"source":["## Coefficient de corrélation"]},{"cell_type":"markdown","metadata":{"id":"2e-cCptTzy6C"},"source":["Calculer le coefficient de corrélation entre `x`et `y`."]},{"cell_type":"code","metadata":{"id":"40PcSzn4zy6C"},"source":["# rho = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MMbZ6xtJzy6E"},"source":["Ce coefficient de corrélation est faible, indiquant qu'une régression linéaire simple n'est certainement pas le modèle adéquat pour lier `y` à `x`. Nous allons toutefois voir que malgré ce faible coefficient de corrélation, il est possible de relier mathématiquement `y` et `x` en utilisant ici la régression polynomiale."]},{"cell_type":"markdown","metadata":{"id":"P8nA4Xy5zy6E"},"source":["# Interpolation des données par une régression polynomiale"]},{"cell_type":"markdown","metadata":{"id":"meOfnHIvzy6F"},"source":["Effectuer une régression polynomiale sur l'ensemble du jeu de données (`x`, `y`) en utilisant la librairie `scikit-learn`. Tester différentes valeurs de degrés de polynômes et calculer les erreurs quadratiques moyennes associées ainsi que leurs racines carrées. Afficher sur un graphique les prédictions obtenues."]},{"cell_type":"markdown","metadata":{"id":"TpASseBtzy6F"},"source":["## Régression polynomiale"]},{"cell_type":"code","metadata":{"id":"HRbfzFeHzy6F"},"source":["d = 2 # degré du polynome\n","Poly = PolynomialFeatures(d) # creation de mon polynome de degré d\n","X_poly = Poly.fit_transform(x)\n","print(X_poly.shape)\n","print(X_poly[0:5, :])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j50l8dylzy6G"},"source":["## Erreur quadratique moyenne"]},{"cell_type":"code","metadata":{"id":"fCLROkOYzy6G"},"source":["# y_predict = ...\n","\n","# MSE = ...\n","# RMSE = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wlnv-Cx_zy6G"},"source":["## Affichage"]},{"cell_type":"code","metadata":{"id":"HpSb3zg2zy6H"},"source":["# plt.plot(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IOatrdJbzy6H"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"XGrl-zu8zy6H"},"source":["![](figure2.png)"]},{"cell_type":"markdown","metadata":{"id":"DPAAk06Lzy6I"},"source":["## Ensuite..."]},{"cell_type":"markdown","metadata":{"id":"7TlsJeMMzy6J"},"source":["Calculer la valeur du degré `d` (1 < `d` < 20) du polynôme minimisant l'erreur quadratique moyenne."]},{"cell_type":"code","metadata":{"id":"AOLFEpvVzy6J"},"source":["# min_MSE = np.inf\n","\n","# for d in range(20):\n","    # ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1nDa1F4Ezy6J"},"source":["Vous avez dû identifier un polynôme de degré 11 comme étant celui qui minimise au mieux l'erreur quadratique moyenne. Toutefois en réalité, les variables `x`et `y` sont reliées entre elles par un polynôme de degré 4. Nous faisons ici face à un problème traditionnel en traitement de la donnée, le sur-apprentissage ou \"overfitting\". Nous allons voir dans la section précédente une méthode pour s'en affranchir."]},{"cell_type":"markdown","metadata":{"id":"7CdRES_tzy6K"},"source":["# Approche Machine Learning"]},{"cell_type":"markdown","metadata":{"id":"UDLLxE85zy6K"},"source":["Un modèle de Machine Learning est typiquement défini par :\n","* des paramètres ;\n","* des hyper-paramètres.\n","\n","Un modèle polynomial a plusieurs paramètres : les coefficients du polynôme $\\theta_{0}, \\theta_{1}, \\ldots, \\theta_{d}$. Il n'a par contre qu'un seul hyperparamètre, le degré $d$ du polynôme.\n","\n","Vous allez dans cette section apprendre, sur l'exemple de la régression polynomiale, comment dans un projet de Machine Learning le jeu de données est échantillonné afin :\n","* de calculer les paramètres du modèle ;\n","* d'optimiser les hyperparamèters du modèle ;\n","* d'éviter le phénomène de sur-apprentissage."]},{"cell_type":"markdown","metadata":{"id":"g3Hny514zy6K"},"source":["## Echantillonnage des données"]},{"cell_type":"markdown","metadata":{"id":"7T-PLHmvzy6L"},"source":["Créer trois jeu de données :\n","* le jeu d'apprentissage constitué de 60% des données ;\n","* le jeu de validation constitué de 20% des données ;\n","* le jeu de test consituté de 20% des données.\n","\n","Fixer la variable `random_state` à 42 pour que nous puissions tous comparer nos résultats."]},{"cell_type":"code","metadata":{"id":"CEAyhLQtzy6L"},"source":["# print(x_test.shape) # (200,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2LfwhQxczy6L"},"source":["# print(y_test.shape) # (200,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wlbr6fZwzy6M"},"source":["# print(x_train.shape) # (600,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TEWVmC7Ezy6M"},"source":["# print(y_train.shape) # (600,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zhPlliQczy6M"},"source":["# print(x_validation.shape) (200,)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TY3XOyIFzy6N"},"source":["# print(y_validation.shape) (200,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NhXJvDgtzy6O"},"source":["Afficher sur un graphique les trois jeux de données."]},{"cell_type":"code","metadata":{"id":"7HYAGTBozy6O"},"source":["# plt.plot(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOdxGnsczy6O"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"UlULvzWczy6O"},"source":["![](figure3.png)"]},{"cell_type":"markdown","metadata":{"id":"1yvr7bXdzy6O"},"source":["# Entrainement du modèle"]},{"cell_type":"markdown","metadata":{"id":"1-OSZjbyzy6P"},"source":["Calculer la valeur du degré `d` du polynôme qui minimise l'erreur quadratique moyenne.\n","\n","Pour cela, nous allons tester 20 valeurs de degré `d` ($0 < d < 21$).\n","\n","Commencer par affecter la valeur 1 à la variable `d`. Effectuer une régression polynomiale sur le jeu d'apprentissage. Calculer l'erreur quadratique moyenne obtenue sur le jeu de validation. Répéter l'opération pour $d = 2, d = 3, \\ldots, d = 20$. \n","\n","La valeur du degré `d` du polynôme qui donne l'erreur quadratique moyenne la plus faible sur le jeu de validation est celle à retenir. (Vous le savez déjà, la bonne réponse est $d = 4$.)"]},{"cell_type":"code","metadata":{"id":"3-iKDtN5zy6P"},"source":["# min_validation_MSE = np.inf\n","\n","# for d in range(20):\n","    # ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-KxX_yFpzy6Q"},"source":["Affecter la valeur 4 à la variable `d`. Effectuer une régression polynomiale sur le jeu d'apprentissage. Calculer l'erreur quadratique moyenne sur le jeu de validation. Afficher l'erreur quadratique moyenne et sa racine carrée."]},{"cell_type":"code","metadata":{"id":"4T6IvaBRzy6Q"},"source":["# d = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kiPPXDc2zy6Q"},"source":["Extraire du modèle entrainé les coefficients du polynôme."]},{"cell_type":"code","metadata":{"id":"sJdzAfwwzy6R"},"source":["# time = np.linspace(0, 15, num=31)\n","\n","# theta0 = ...\n","# theta1 = ...\n","# theta2 = ...\n","# theta3 = ...\n","# theta4 = ...\n","\n","#polynomial = theta0 + theta1*time + theta2*time**2 + theta3*time**3 + theta4*time**4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aUrx8GG7zy6S"},"source":["## Données d'apprentissage : affichage des résultats"]},{"cell_type":"markdown","metadata":{"id":"-oO2Z6YXzy6S"},"source":["Calculer l'erreur quadratique moyenne et sa racine carrée obtenues sur les données d'apprentissage."]},{"cell_type":"code","metadata":{"id":"v1s8t3ktzy6S"},"source":["# train_MSE = ...\n","# train_RMSE = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FLbENEslzy6T"},"source":["Afficher sur un graphique les données d'apprentissage et la régression polynomiale obtenue."]},{"cell_type":"code","metadata":{"id":"vvx4HLIUzy6T"},"source":["# plt.plot(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WcM-tUAHzy6T"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"Xlu6EF5Yzy6T"},"source":["![](figure4.png)"]},{"cell_type":"markdown","metadata":{"id":"ROwNOzMpzy6U"},"source":["## Données de validation : affichage des résultats"]},{"cell_type":"markdown","metadata":{"id":"uSodJA1Hzy6U"},"source":["Calculer l'erreur quadratique moyenne et sa racine carrée obtenues sur les données de validation."]},{"cell_type":"code","metadata":{"id":"8Ri3okWHzy6V"},"source":["# validation_MSE = ...\n","# validation_RMSE = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kc2Gk862zy6V"},"source":["Afficher sur un graphique les données de validation et la régression polynomiale obtenue."]},{"cell_type":"code","metadata":{"id":"zIumblYhzy6V"},"source":["# plt.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_hsr0-bJzy6V"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"Xd2Jsrzmzy6W"},"source":["![](figure5.png)"]},{"cell_type":"markdown","metadata":{"id":"0RMHHVXJzy6W"},"source":["# Données de test : évaluation des performances"]},{"cell_type":"markdown","metadata":{"id":"ghKgLMzzzy6W"},"source":["Calculer l'erreur quadratique moyenne et sa racine carrée obtenues sur les données de test."]},{"cell_type":"code","metadata":{"id":"sdVe14cJzy6W"},"source":["# test_MSE = ...\n","# test_RMSE = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o6MN2OAJzy6X"},"source":["Afficher sur un graphique les données de test et la régression polynomiale obtenue."]},{"cell_type":"code","metadata":{"id":"9_rDmINozy6X"},"source":["# plt.plot()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U3pn_LAGzy6Y"},"source":["(Exemple de graphique attendu)"]},{"cell_type":"markdown","metadata":{"id":"MX_UzF9Ezy6Y"},"source":["![](figure6.png)"]},{"cell_type":"markdown","metadata":{"id":"eT2PGIvqzy6Z"},"source":["Effectuer une régression linéaire entre les données de test réelles et les données de test prédites (utiliser Numpy). Calculer la pente `a`, l'ordonnée à l'origine `b` et le coefficient de détermination `R²`."]},{"cell_type":"code","metadata":{"id":"CfKnSur9zy6Z"},"source":["# [a, b] = ...\n","# R2 = ..."],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nte8KZlNzy6Z"},"source":["Afficher sur un graphique les températures prédites en fonction des températures réelles (données de test). Afficher en plus la droite de régression, son équation ainsi que le coefficient de détermination."]},{"cell_type":"code","metadata":{"id":"eGtSg509zy6Z"},"source":["# plt.plot(...)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C4jmrWB6zy6a"},"source":["(Exemple de graphique attentu)"]},{"cell_type":"markdown","metadata":{"id":"2GbXibVLzy6a"},"source":["![](figure7.png)"]},{"cell_type":"code","metadata":{"id":"Pt5ii_xIzy6a"},"source":[""],"execution_count":null,"outputs":[]}]}